{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture Testing\n",
    "\n",
    "Test the model architecture with default configuration before optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 18:05:23.214917: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-15 18:05:23.618321: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-15 18:05:23.619479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 18:05:24.665992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "notebook_dir = Path(os.path.abspath('')).parent\n",
    "build_dir = notebook_dir.parent\n",
    "sys.path.append(str(notebook_dir))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.modeling.architecture import ModelBuilder\n",
    "from src.preprocessing.preprocessor import FeaturePreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "feature_cols = ['mH2', 'mHD', 'mAD', 'mHDp', 'alpha', 'L2', 'L8', 'vs', 'm22sq']\n",
    "label_cols = ['valid_BFB', 'valid_Uni', 'valid_STU', 'valid_Higgs']\n",
    "\n",
    "# Load preprocessor\n",
    "preprocessor = FeaturePreprocessor.load_transformers(os.path.join(build_dir, 'preprocessor'))\n",
    "\n",
    "# Load and preprocess train/val sets\n",
    "train_data = pd.read_csv(os.path.join(build_dir, 'data_splits/train_set.tsv'), sep='\\t')\n",
    "val_data = pd.read_csv(os.path.join(build_dir, 'data_splits/val_set.tsv'), sep='\\t')\n",
    "\n",
    "X_train = preprocessor.transform(train_data[feature_cols])\n",
    "y_train = train_data[label_cols]\n",
    "\n",
    "X_val = preprocessor.transform(val_data[feature_cols])\n",
    "y_val = val_data[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default configuration:\n",
      "n_layers: 3\n",
      "n_units_0: 875\n",
      "n_units_1: 938\n",
      "n_units_2: 402\n",
      "activation: relu\n",
      "dropout_rate: 0.117\n",
      "apply_batch_norm: True\n",
      "optimizer: adam\n",
      "regularization: None\n",
      "reg_lambda: 0.05\n",
      "learning_rate: 0.000263\n"
     ]
    }
   ],
   "source": [
    "# Initialize model builder\n",
    "builder = ModelBuilder(\n",
    "    input_shape=(len(feature_cols),),\n",
    "    num_outputs=len(label_cols)\n",
    ")\n",
    "\n",
    "# Get default configuration\n",
    "config = ModelBuilder.get_default_config()\n",
    "print(\"Default configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 875)               8750      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 875)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 875)              3500      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 875)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 938)               821688    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 938)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 938)              3752      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 938)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 402)               377478    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 402)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 402)              1608      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 402)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 1612      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,218,388\n",
      "Trainable params: 1,213,958\n",
      "Non-trainable params: 4,430\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 18:06:21.663723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: maienPC\n",
      "2025-01-15 18:06:21.663741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: maienPC\n",
      "2025-01-15 18:06:21.663855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2025-01-15 18:06:21.663884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.239.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 9s 88ms/step - loss: 0.1342 - subset_accuracy: 0.4462 - hamming_loss: 0.1837 - matthews_correlation: 0.6269 - macro_f1_score: 0.8409 - val_loss: 0.1338 - val_subset_accuracy: 0.3402 - val_hamming_loss: 0.2326 - val_matthews_correlation: 0.5421 - val_macro_f1_score: 0.8260\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.0881 - subset_accuracy: 0.5493 - hamming_loss: 0.1371 - matthews_correlation: 0.7217 - macro_f1_score: 0.8830 - val_loss: 0.1287 - val_subset_accuracy: 0.3498 - val_hamming_loss: 0.2490 - val_matthews_correlation: 0.5429 - val_macro_f1_score: 0.8240\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.0746 - subset_accuracy: 0.6006 - hamming_loss: 0.1179 - matthews_correlation: 0.7609 - macro_f1_score: 0.8993 - val_loss: 0.1366 - val_subset_accuracy: 0.3829 - val_hamming_loss: 0.2240 - val_matthews_correlation: 0.5893 - val_macro_f1_score: 0.8381\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.0660 - subset_accuracy: 0.6396 - hamming_loss: 0.1041 - matthews_correlation: 0.7889 - macro_f1_score: 0.9112 - val_loss: 0.1111 - val_subset_accuracy: 0.4722 - val_hamming_loss: 0.1771 - val_matthews_correlation: 0.6712 - val_macro_f1_score: 0.8673\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.0610 - subset_accuracy: 0.6660 - hamming_loss: 0.0954 - matthews_correlation: 0.8068 - macro_f1_score: 0.9186 - val_loss: 0.0838 - val_subset_accuracy: 0.5672 - val_hamming_loss: 0.1357 - val_matthews_correlation: 0.7447 - val_macro_f1_score: 0.8944\n"
     ]
    }
   ],
   "source": [
    "# Build and train model\n",
    "model = builder.build_model(config)\n",
    "model.summary()\n",
    "\n",
    "# Train for a few epochs to verify everything works\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
